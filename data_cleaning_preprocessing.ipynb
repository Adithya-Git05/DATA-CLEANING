# prompt: input a csv file

from google.colab import files
uploaded = files.upload()




# read the csv file
import pandas as pd
data = pd.read_csv('diabetes.csv')

data.head()

data.describe()

len(data['Pregnancies'])

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

data.hist(bins=20, figsize=(15, 10), color='skyblue', edgecolor='black')
plt.suptitle('Feature Distributions Before Preprocessing', fontsize=16)
plt.tight_layout()
plt.show()

# Columns where 0 is considered as missing
columns_with_zero_as_missing = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']

# Replace zeros with NaN for these columns
data[columns_with_zero_as_missing] = data[columns_with_zero_as_missing].replace(0, np.nan)

# Check for missing values
print(data.isnull().sum())
data.head()

# Fill missing values with median
for column in columns_with_zero_as_missing:
    data[column].fillna(data[column].median(), inplace=True)

# Verify no missing values
print(data.isnull().sum())


data.head()

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
numerical_columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness',
                     'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']
data[numerical_columns] = scaler.fit_transform(data[numerical_columns])

# Display normalized data
data.head()



plt.figure(figsize=(10, 8))
sns.heatmap(data.corr(), annot=True, cmap='coolwarm')
plt.title('Correlation Heatmap')
plt.show()


import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# Separate features (X) and target (y)
X = data.drop(columns=['Outcome'])  # All columns except 'Outcome'
y = data['Outcome']                # Target variable



# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create and train the Linear Regression model
linear_model = LinearRegression()
linear_model.fit(X_train, y_train)

# Make predictions
y_pred_linear = linear_model.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred_linear)
r2 = r2_score(y_test, y_pred_linear)

print("Linear Regression Results:")
print(f"Mean Squared Error: {mse}")
print(f"R^2 Score: {r2}")

# import matplotlib.pyplot as plt

# # Plot Actual vs Predicted for Linear Regression
# plt.figure(figsize=(8, 6))
# plt.scatter(y_test, y_pred_linear, color='blue', alpha=0.7, label='Linear Regression')
# plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', color='red', label='Ideal Fit')
# plt.xlabel('Actual Outcome')
# plt.ylabel('Predicted Outcome')
# plt.title('Actual vs Predicted (Linear Regression)')
# plt.legend()
# plt.grid()
# plt.show()


from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline

# Choose the degree of the polynomial
degree = 2  # You can experiment with higher degrees

# Create a pipeline for Polynomial Regression
poly_model = make_pipeline(PolynomialFeatures(degree), LinearRegression())
poly_model.fit(X_train, y_train)

# Make predictions
y_pred_poly = poly_model.predict(X_test)

# Evaluate the model
mse_poly = mean_squared_error(y_test, y_pred_poly)
r2_poly = r2_score(y_test, y_pred_poly)

print("\nPolynomial Regression Results:")
print(f"Mean Squared Error: {mse_poly}")
print(f"R^2 Score: {r2_poly}")


#0.352941	0.743719	0.590164	0.353535	0.000000	0.500745	0.234415	0.483333	1

# import numpy as np

# # Example single input: replace with your own values
# single_input = np.array([[6, 148, 72, 35, 0, 33.6, 0.627, 50]])
# # scaler.fit_transform(single_input)
# # Prediction using Linear Regression
# single_pred_linear = linear_model.predict(single_input)
# print(f"Linear Regression Prediction for Single Input: {single_pred_linear[0]}")

# # Prediction using Polynomial Regression
# single_pred_poly = poly_model.predict(single_input)
# print(f"Polynomial Regression Prediction for Single Input: {single_pred_poly[0]}")
